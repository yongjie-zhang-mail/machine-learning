{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 卷积神经网络（LeNet）\n",
    ":label:`sec_lenet`\n",
    "\n",
    "通过之前几节，我们学习了构建一个完整卷积神经网络的所需组件。\n",
    "回想一下，之前我们将softmax回归模型（ :numref:`sec_softmax_scratch`）和多层感知机模型（ :numref:`sec_mlp_scratch`）应用于Fashion-MNIST数据集中的服装图片。\n",
    "为了能够应用softmax回归和多层感知机，我们首先将每个大小为$28\\times28$的图像展平为一个784维的固定长度的一维向量，然后用全连接层对其进行处理。\n",
    "而现在，我们已经掌握了卷积层的处理方法，我们可以在图像中保留空间结构。\n",
    "同时，用卷积层代替全连接层的另一个好处是：模型更简洁、所需的参数更少。\n",
    "\n",
    "在本节中，我们将介绍LeNet，它是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。\n",
    "这个模型是由AT&T贝尔实验室的研究员Yann LeCun在1989年提出的（并以其命名），目的是识别图像 :cite:`LeCun.Bottou.Bengio.ea.1998`中的手写数字。\n",
    "当时，Yann LeCun发表了第一篇通过反向传播成功训练卷积神经网络的研究，这项工作代表了十多年来神经网络研究开发的成果。\n",
    "\n",
    "当时，LeNet取得了与支持向量机（support vector machines）性能相媲美的成果，成为监督学习的主流方法。\n",
    "LeNet被广泛用于自动取款机（ATM）机中，帮助识别处理支票的数字。\n",
    "时至今日，一些自动取款机仍在运行Yann LeCun和他的同事Leon Bottou在上世纪90年代写的代码呢！\n",
    "\n",
    "## LeNet\n",
    "\n",
    "总体来看，(**LeNet（LeNet-5）由两个部分组成：**)\n",
    "\n",
    "* 卷积编码器：由两个卷积层组成;\n",
    "* 全连接层密集块：由三个全连接层组成。\n",
    "\n",
    "该架构如 :numref:`img_lenet`所示。\n",
    "\n",
    "![LeNet中的数据流。输入是手写数字，输出为10种可能结果的概率。](../img/lenet.svg)\n",
    ":label:`img_lenet`\n",
    "\n",
    "每个卷积块中的基本单元是一个卷积层、一个sigmoid激活函数和平均汇聚层。请注意，虽然ReLU和最大汇聚层更有效，但它们在20世纪90年代还没有出现。每个卷积层使用$5\\times 5$卷积核和一个sigmoid激活函数。这些层将输入映射到多个二维特征输出，通常同时增加通道的数量。第一卷积层有6个输出通道，而第二个卷积层有16个输出通道。每个$2\\times2$池操作（步骤2）通过空间下采样将维数减少4倍。卷积的输出形状由批量大小、通道数、高度、宽度决定。\n",
    "\n",
    "为了将卷积块的输出传递给稠密块，我们必须在小批量中展平每个样本。换言之，我们将这个四维输入转换成全连接层所期望的二维输入。这里的二维表示的第一个维度索引小批量中的样本，第二个维度给出每个样本的平面向量表示。LeNet的稠密块有三个全连接层，分别有120、84和10个输出。因为我们在执行分类任务，所以输出层的10维对应于最后输出结果的数量。\n",
    "\n",
    "通过下面的LeNet代码，你会相信用深度学习框架实现此类模型非常简单。我们只需要实例化一个`Sequential`块并将需要的层连接在一起。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "我们对原始模型做了一点小改动，去掉了最后一层的高斯激活。除此之外，这个网络与最初的LeNet-5一致。\n",
    "\n",
    "下面，我们将一个大小为$28 \\times 28$的单通道（黑白）图像通过LeNet。通过在每一层打印输出的形状，我们可以[**检查模型**]，以确保其操作与我们期望的 :numref:`img_lenet_vert`一致。\n",
    "\n",
    "![LeNet 的简化版。](../img/lenet-vert.svg)\n",
    ":label:`img_lenet_vert`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape: \t torch.Size([1, 6, 28, 28])\n",
      "Sigmoid output shape: \t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape: \t torch.Size([1, 16, 10, 10])\n",
      "Sigmoid output shape: \t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape: \t torch.Size([1, 400])\n",
      "Linear output shape: \t torch.Size([1, 120])\n",
      "Sigmoid output shape: \t torch.Size([1, 120])\n",
      "Linear output shape: \t torch.Size([1, 84])\n",
      "Sigmoid output shape: \t torch.Size([1, 84])\n",
      "Linear output shape: \t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape: \\t',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "请注意，在整个卷积块中，与上一层相比，每一层特征的高度和宽度都减小了。\n",
    "第一个卷积层使用2个像素的填充，来补偿$5 \\times 5$卷积核导致的特征减少。\n",
    "相反，第二个卷积层没有填充，因此高度和宽度都减少了4个像素。\n",
    "随着层叠的上升，通道的数量从输入时的1个，增加到第一个卷积层之后的6个，再到第二个卷积层之后的16个。\n",
    "同时，每个汇聚层的高度和宽度都减半。最后，每个全连接层减少维数，最终输出一个维数与结果分类数相匹配的输出。\n",
    "\n",
    "## 模型训练\n",
    "\n",
    "现在我们已经实现了LeNet，让我们看看[**LeNet在Fashion-MNIST数据集上的表现**]。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "origin_pos": 9,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "虽然卷积神经网络的参数较少，但与深度的多层感知机相比，它们的计算成本仍然很高，因为每个参数都参与更多的乘法。\n",
    "如果你有机会使用GPU，可以用它加快训练。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "为了进行评估，我们需要[**对**] :numref:`sec_softmax_scratch`中描述的(**`evaluate_accuracy`函数进行轻微的修改**)。\n",
    "由于完整的数据集位于内存中，因此在模型使用GPU计算数据集之前，我们需要将其复制到显存中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "origin_pos": 13,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gpu(net, data_iter, device=None): #@save\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # 正确预测的数量，总预测的数量\n",
    "    metric = d2l.Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # BERT微调所需的（之后将介绍）\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(d2l.accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 14
   },
   "source": [
    "[**为了使用GPU，我们还需要一点小改动**]。\n",
    "与 :numref:`sec_softmax_scratch`中定义的`train_epoch_ch3`不同，在进行正向和反向传播之前，我们需要将每一小批量数据移动到我们指定的设备（例如GPU）上。\n",
    "\n",
    "如下所示，训练函数`train_ch6`也类似于 :numref:`sec_softmax_scratch`中定义的`train_ch3`。\n",
    "由于我们将实现多层神经网络，因此我们将主要使用高级API。\n",
    "以下训练函数假定从高级API创建的模型作为输入，并进行相应的优化。\n",
    "我们使用在 :numref:`subsec_xavier`中介绍的Xavier随机初始化模型参数。\n",
    "与全连接层一样，我们使用交叉熵损失函数和小批量随机梯度下降。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "origin_pos": 16,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"用GPU训练模型(在第六章定义)\"\"\"\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练损失之和，训练准确率之和，样本数\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                # X 维度：样本数、通道、高度、宽度\n",
    "                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (train_l, train_acc, None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "          f'on {str(device)}')\n",
    "    \n",
    "def train_ch6_2(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"用GPU训练模型(在第六章定义)\"\"\"\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        \n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "                       \n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # X 维度：样本数、通道、高度、宽度\n",
    "                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            \n",
    "            timer.stop()\n",
    "        \n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches, (train_l, train_acc, None))\n",
    "                \n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "        \n",
    "        \n",
    "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "          f'on {str(device)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 18
   },
   "source": [
    "现在，我们[**训练和评估LeNet-5模型**]。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:0, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:1, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:2, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:3, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:4, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:5, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:6, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:7, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:8, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:9, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:10, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:11, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:12, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:13, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:14, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:15, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:16, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:17, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:18, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:19, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:20, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:21, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:22, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:23, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:24, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:25, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:26, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:27, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:28, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:29, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:30, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:31, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:32, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:33, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:34, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:35, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:36, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:37, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:38, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:39, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:40, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:41, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:42, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:43, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:44, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:45, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:46, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:47, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:48, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:49, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:50, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:51, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:52, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:53, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:54, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:55, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:56, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:57, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:58, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:59, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:60, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:61, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:62, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:63, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:64, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:65, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:66, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:67, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:68, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:69, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:70, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:71, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:72, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:73, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:74, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:75, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:76, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:77, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:78, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:79, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:80, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:81, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:82, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:83, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:84, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:85, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:86, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:87, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:88, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:89, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:90, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:91, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:92, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:93, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:94, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:95, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:96, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:97, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:98, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:99, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:100, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:101, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:102, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:103, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:104, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:105, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:106, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:107, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:108, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:109, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:110, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:111, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:112, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:113, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:114, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:115, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:116, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:117, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:118, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:119, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:120, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:121, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:122, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:123, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:124, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:125, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:126, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:127, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:128, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:129, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:130, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:131, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:132, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:133, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:134, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:135, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:136, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:137, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:138, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:139, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:140, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:141, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:142, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:143, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:144, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:145, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:146, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:147, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:148, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:149, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:150, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:151, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:152, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:153, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:154, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:155, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:156, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:157, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:158, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:159, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:160, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:161, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:162, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:163, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:164, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:165, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:166, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:167, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:168, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:169, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:170, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:171, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:172, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:173, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:174, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:175, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:176, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:177, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:178, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:179, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:180, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:181, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:182, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:183, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:184, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:185, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:186, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:187, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:188, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:189, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:190, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:191, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:192, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:193, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:194, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:195, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:196, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:197, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:198, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:199, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:200, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:201, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:202, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:203, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:204, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:205, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:206, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:207, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:208, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:209, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:210, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:211, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:212, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:213, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:214, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:215, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:216, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:217, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:218, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:219, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:220, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:221, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:222, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:223, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:224, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:225, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:226, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:227, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:228, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:229, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:230, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:231, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:232, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:233, X.shape:torch.Size([256, 1, 28, 28]), y.shape:torch.Size([256])\n",
      "i:234, X.shape:torch.Size([96, 1, 28, 28]), y.shape:torch.Size([96])\n"
     ]
    }
   ],
   "source": [
    "# 235\n",
    "# len(train_iter)\n",
    "# for i, (X, y) in enumerate(train_iter):\n",
    "#     print(f'i:{i}, X.shape:{X.shape}, y.shape:{y.shape}')\n",
    "\n",
    "lr, num_epochs = 0.9, 10\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 卷积神经网络（CNN）是一类使用卷积层的网络。\n",
    "* 在卷积神经网络中，我们组合使用卷积层、非线性激活函数和汇聚层。\n",
    "* 为了构造高性能的卷积神经网络，我们通常对卷积层进行排列，逐渐降低其表示的空间分辨率，同时增加通道数。\n",
    "* 在传统的卷积神经网络中，卷积块编码得到的表征在输出之前需由一个或多个全连接层进行处理。\n",
    "* LeNet是最早发布的卷积神经网络之一。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 将平均汇聚层替换为最大汇聚层，会发生什么？\n",
    "1. 尝试构建一个基于LeNet的更复杂的网络，以提高其准确性。\n",
    "    1. 调整卷积窗口大小。\n",
    "    1. 调整输出通道的数量。\n",
    "    1. 调整激活函数（如ReLU）。\n",
    "    1. 调整卷积层的数量。\n",
    "    1. 调整全连接层的数量。\n",
    "    1. 调整学习率和其他训练细节（例如，初始化和轮数）。\n",
    "1. 在MNIST数据集上尝试以上改进的网络。\n",
    "1. 显示不同输入（例如毛衣和外套）时，LeNet第一层和第二层的激活值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1860)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
