{"cells":[{"cell_type":"markdown","id":"1dfae479-9399-492d-acaa-d9751615ee86","metadata":{"id":"1dfae479-9399-492d-acaa-d9751615ee86","tags":[]},"source":["# 第六章 微调语言模型\n","\n"," - [一. 微调语言模型的重要性](#一.-微调语言模型的重要性)\n"," - [二. 使用 Hugging Face 微调语言模型](#二.-使用-Hugging-Face-微调语言模型)\n","     - [2.1  数据处理](#2.1--数据处理)\n","     - [2.2 模型训练](#2.2-模型训练)\n"," - [三. 模型训练结果的实时查看和分析](#三.-模型训练结果的实时查看和分析)\n"]},{"cell_type":"markdown","id":"80133889","metadata":{"id":"80133889"},"source":["## 一. 微调语言模型的重要性"]},{"cell_type":"markdown","id":"349c1725","metadata":{},"source":["![compare-method.png](../../figures/compare-method.png)"]},{"cell_type":"markdown","id":"60b15293","metadata":{"id":"60b15293"},"source":["从头开始训练语言模型需要耗费大量时间和资源，而对这些模型进行评估同样需要复杂且资源密集的工作。因此，务必密切留意训练过程，并利用 `checkpoint` 来妥善应对可能出现的意外问题。仪表板（`dashboard`）是一个宝贵的工具，可以展示训练的进度和指标，并且在需要时提供 `checkpoint`。这样可以帮助您及时了解模型的性能，并保证训练过程的顺利进行。\n","\n","微调语言模型是一种更经济高效的优化方式，特别是在计算资源有限的情况下。然而，在评估过程中仍然需要保持谨慎。根据使用语言模型的目标，可以制定出适合的评估策略，以确保模型达到所需的性能水平。"]},{"cell_type":"markdown","id":"28313d52","metadata":{"id":"28313d52"},"source":["## 二. 使用 Hugging Face 微调语言模型\n","\n","在本课程中，我们将展示如何使用 Hugging Face 微调语言模型。为了在 CPU 上高效地进行这项工作，我们将使用一个名为 `TinyStories` 的小型语言模型，它拥有 3300 万个参数。我们将在《龙与地下城》游戏世界的角色背景故事数据集上微调这个轻量级模型。"]},{"cell_type":"code","execution_count":1,"id":"a1f0e67f","metadata":{"height":149,"id":"a1f0e67f"},"outputs":[],"source":["from transformers import AutoTokenizer\n","from datasets import load_dataset\n","from transformers import AutoModelForCausalLM\n","from transformers import Trainer, TrainingArguments\n","import transformers\n","transformers.set_seed(42)\n","\n","import wandb"]},{"cell_type":"code","execution_count":2,"id":"f79c25e3-5f18-4457-84e1-ed2c0d262222","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"height":30,"id":"f79c25e3-5f18-4457-84e1-ed2c0d262222","outputId":"114817d7-e8e4-49f8-f13e-9aca370cf89d"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manony-moose-980007700204230807\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login(anonymous=\"allow\")"]},{"cell_type":"markdown","id":"b2d1b5e0","metadata":{},"source":["AutoClasses 从提供给 from_pretrained() 方法的预训练模型的名称或路径中猜测要使用的架构。\n","\n","AutoConfig、AutoModel 和 AutoTokenizer 可以根据名称/路径自动检索相关模型。\n","\n","- 远程：huggingface.co 的仓库中根级别的表示，如 bert-base-uncased，或用户或组织名称下的命名空间，如 roneneldan/TinyStories-33M\n","- 本地：用 save_pretrained() 方法保存的目录"]},{"cell_type":"code","execution_count":3,"id":"2286ae41-213d-480d-a4ba-8c4e2e1c4771","metadata":{"height":30,"id":"2286ae41-213d-480d-a4ba-8c4e2e1c4771"},"outputs":[],"source":["model_checkpoint = \"roneneldan/TinyStories-33M\""]},{"cell_type":"markdown","id":"3fd80268-c4a1-4e1a-aed3-cd5c3ab4d48f","metadata":{"id":"3fd80268-c4a1-4e1a-aed3-cd5c3ab4d48f"},"source":["### 2.1  数据处理\n","\n","首先，我们将从 Huggingface 加载一个[包含《龙与地下城》角色背景故事的数据集](https://huggingface.co/datasets/MohamedRashad/characters_backstories)。"]},{"cell_type":"code","execution_count":4,"id":"a7535b8b-d220-44e8-a56c-97e250c36596","metadata":{"height":30,"id":"a7535b8b-d220-44e8-a56c-97e250c36596"},"outputs":[],"source":["ds = load_dataset('MohamedRashad/characters_backstories')"]},{"cell_type":"code","execution_count":5,"id":"13caeb7f-8a07-4ca2-a770-5b627238c2ac","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"height":47,"id":"13caeb7f-8a07-4ca2-a770-5b627238c2ac","outputId":"3c3e8c39-da3c-4bd4-b49e-8753104ca66f"},"outputs":[{"data":{"text/plain":["{'text': 'Generate Backstory based on following information\\nCharacter Name: Dewin \\nCharacter Race: Halfling\\nCharacter Class: Sorcerer bard\\n\\nOutput:\\n',\n"," 'target': 'Dewin thought he was a wizard, but it turned out it was the draconic blood in his veins that brought him eldritch power.  Music classes in wizarding college taught him yet another use for his power, and when he was expelled he took up adventuring'}"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# 让我们来看一个例子\n","ds[\"train\"][400]"]},{"cell_type":"markdown","id":"z1XC0CU0Sidb","metadata":{"id":"z1XC0CU0Sidb"},"source":["这个数据集包含两列：一列是文本，要求模型生成一个背景故事；另一列是目标，保存了角色的背景故事。\n","\n","我们将对数据集进行分割，以便创建一个验证集。"]},{"cell_type":"code","execution_count":6,"id":"7dae9106-8015-43da-a6d9-1124dee4bdde","metadata":{"height":47,"id":"7dae9106-8015-43da-a6d9-1124dee4bdde"},"outputs":[],"source":["# 由于该数据集没有预先分割的验证集，我们需要自行创建\n","ds = ds[\"train\"].train_test_split(test_size=0.2, seed=42)"]},{"cell_type":"markdown","id":"R3jGH1eRLPGu","metadata":{"id":"R3jGH1eRLPGu"},"source":["在训练模型之前，我们需要将 text（角色信息） 和 target（背景故事） 进行拼接，并确保它们经过正确的分词和填充处理。\n","\n","在这一过程中，Hugging Face 框架会自动为每个输入标记分配相应的正确 label，并将其用于模型的训练。由于模型需要预测序列中的下一个标记，Hugging Face 会自动将原始内容作为 label，并将这些 label 向右移动一个位置，以便模型能够正确地预测序列中的下一个标记。\n","\n"]},{"cell_type":"markdown","id":"405f42f7","metadata":{},"source":["[AutoTokenizer](https://huggingface.co/learn/nlp-course/zh-CN/chapter6/1?fw=pt) 将会帮助我们获得预训练模型对应的 tokenizer，使模型处理预料与训练时保持一致。"]},{"cell_type":"code","execution_count":7,"id":"7ea1602d-504b-43de-87ad-fcb35b9e61f7","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":77,"referenced_widgets":["392a389d2b3e4469a4d97e25905db827","2687806020864ec8a02e9c237b168a1b","e7b21c44f91d41acbeeb9a5b756de8db","e844acd81ba64610b5a489d678ca83ec","b0e68cd5eef94c87b9d694777f4d4bd6","efc62b9109b64216b0e1463c4aad5edf","67c75cf288834525a38d4779d9344515","ac69ce5800a44e2e88ac6e0db675f770","008d4419e82f46be82d2a5f50ba1bd86","a6768ce6f36740f39bd3866ffb6339fe","98928bfce80146d889963509e0d43f88"]},"height":268,"id":"7ea1602d-504b-43de-87ad-fcb35b9e61f7","outputId":"a424c9de-3452-42fa-f60a-ccf056a1d104"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"392a389d2b3e4469a4d97e25905db827","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/465 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# 我们将从模型 checkpoint 创建一个 tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=False)\n","\n","# 我们需要对样本进行 padding，以便在批次中使用相同长度的序列\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# 将文本和目标首先进行拼接。然后使用 tokenizer 对拼接后的字符串进行分词\n","def tokenize_function(example):\n","    merged = example[\"text\"] + \" \" + example[\"target\"]\n","    batch = tokenizer(merged, padding='max_length', truncation=True, max_length=128)\n","    batch[\"labels\"] = batch[\"input_ids\"].copy()\n","    return batch\n","\n","# 将其应用于我们的数据集，并删除文本列\n","tokenized_datasets = ds.map(tokenize_function, remove_columns=[\"text\", \"target\"])"]},{"cell_type":"markdown","id":"c9288a8e-b19b-4bd2-a72c-7dda03632282","metadata":{"id":"c9288a8e-b19b-4bd2-a72c-7dda03632282"},"source":["> 您可能会在这里收到一些警告，这没关系"]},{"cell_type":"markdown","id":"62488d0c","metadata":{"id":"62488d0c"},"source":["在开始模型训练前，我们会先验证一下生成样本的质量，以确保一切正常。当我们进行解码输出时，您将首先看到一些指令，然后是生成的背景故事。如果一切看起来都很好，我们就可以继续了。"]},{"cell_type":"code","execution_count":8,"id":"a42417b8-ffa8-4d96-92ea-d8d949d87d5e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"height":47,"id":"a42417b8-ffa8-4d96-92ea-d8d949d87d5e","outputId":"20b687ad-bae8-4052-d4e8-23d29e5a6a06"},"outputs":[{"name":"stdout","output_type":"stream","text":["Generate Backstory based on following information\n","Character Name: Mr. Gale\n","Character Race: Half-orc\n","Character Class: Cleric\n","\n","Output:\n"," Growing up the only half-orc in a small rural town was rough. His mother didn't survive childbirth and so was raised in a church in a high mountain pass, his attention was always drawn by airships passing through, and dreams of an escape. Leaving to strike out on his own as early as he could he made a living for most of his life as an airship sailor, and occasionally a pirate. A single storm visits him throughout his life, marking every major\n"]}],"source":["# 让我们看看一个准备好的例子\n","print(tokenizer.decode(tokenized_datasets[\"train\"][900]['input_ids']))"]},{"cell_type":"markdown","id":"2e8d6b17-a63d-41f1-92cf-416064b52156","metadata":{"id":"2e8d6b17-a63d-41f1-92cf-416064b52156"},"source":["### 2.2 模型训练\n","我们将使用 Hugging Face 的 Transformers，及其 wandb 集成在数据集上微调预训练的语言模型。\n","\n","我们创建的模型用于因果语言建模，这意味着它是一个自回归语言模型，类似于 GPT。它的任务是预测序列中的下一个词。我们将开始一个新的 Weights & Biases 运行，工作类型设置为训练。接下来，我们需要定义一些训练参数，比如训练周期数、学习率、权重衰减，并且非常重要的是，我们将设置 `wandb` 作为报告机制。这意味着您的所有结果将汇集到同一个集中仪表板中。这是您所需要做的一切，以确保指标的流动展示。"]},{"cell_type":"markdown","id":"7fb6f719","metadata":{},"source":["[AutoModelForCausalLM](https://huggingface.co/learn/nlp-course/zh-CN/chapter2/3) 会从 checkpoint 自动载入对应的因果语言模型。"]},{"cell_type":"code","execution_count":9,"id":"b4f131eb-979e-40f6-9e28-19756beaa8e4","metadata":{"height":47,"id":"b4f131eb-979e-40f6-9e28-19756beaa8e4"},"outputs":[],"source":["# 我们将根据预训练的检查点来训练因果（自回归）语言模型\n","model = AutoModelForCausalLM.from_pretrained(model_checkpoint);"]},{"cell_type":"code","execution_count":10,"id":"7345ab23-8d12-4d4c-a39d-bb2202bff218","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"height":47,"id":"7345ab23-8d12-4d4c-a39d-bb2202bff218","outputId":"419b1376-d8c8-41ee-cb1c-614a239bd86a"},"outputs":[{"data":{"text/html":["Tracking run with wandb version 0.15.8"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230813_134429-8o77rmiz</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning/runs/8o77rmiz?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88' target=\"_blank\">sandy-river-2</a></strong> to <a href='https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88' target=\"_blank\">https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning/runs/8o77rmiz?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88' target=\"_blank\">https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning/runs/8o77rmiz?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Do NOT share these links with anyone. They can be used to claim your runs."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# 启动新的 wandb 运行\n","run = wandb.init(project='dlai_lm_tuning', job_type=\"training\", anonymous=\"allow\")"]},{"cell_type":"code","execution_count":11,"id":"d74ee155-3c30-4ef2-9c4d-fd8ee222c50c","metadata":{"height":217,"id":"d74ee155-3c30-4ef2-9c4d-fd8ee222c50c"},"outputs":[],"source":["# 定义训练参数\n","model_name = model_checkpoint.split(\"/\")[-1]\n","training_args = TrainingArguments(\n","    f\"{model_name}-finetuned-characters-backstories\",\n","    report_to=\"wandb\", # 我们需要一行来跟踪 wandb 中的实验\n","    num_train_epochs=1,\n","    logging_steps=1,\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=1e-4,\n","    weight_decay=0.01,\n","    no_cuda=True, # 强制使用 CPU，将改为 use_cpu\n",")"]},{"cell_type":"code","execution_count":12,"id":"af62105f-a478-436f-88a2-5c1d78b9d20a","metadata":{"height":132,"id":"af62105f-a478-436f-88a2-5c1d78b9d20a"},"outputs":[],"source":["# 我们将使用 HF Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n",")"]},{"cell_type":"code","execution_count":13,"id":"01958a56-c22a-4a27-bc71-41c59fc97f05","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":234},"height":47,"id":"01958a56-c22a-4a27-bc71-41c59fc97f05","outputId":"0e6a2ddb-a6f4-4a7a-85b7-deb77e7e657f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='233' max='233' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [233/233 31:46, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.804500</td>\n","      <td>3.350718</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=233, training_loss=3.7419421836541957, metrics={'train_runtime': 1912.6777, 'train_samples_per_second': 0.971, 'train_steps_per_second': 0.122, 'total_flos': 40423258718208.0, 'train_loss': 3.7419421836541957, 'epoch': 1.0})"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# 开始训练\n","trainer.train()"]},{"cell_type":"markdown","id":"7d5eb6e0","metadata":{"id":"7d5eb6e0"},"source":["## 三. 模型训练结果的实时查看和分析\n","\n","在模型训练过程中，我们可以通过点击链接来实时查看结果。随着时间的推移，我们可以观察到各种指标的变化。其中，我们最关注的指标是训练 loss，我们会持续关注它的变化趋势。在调试模型训练运行时，检查 loss 是否持续下降是非常有用的。因此，您希望看到这个曲线向下并向右移动。\n","\n","对于一些非常大的语言模型，训练可能需要几天甚至几周的时间。因此，拥有一个可以远程查看图表的功能非常有帮助。这样可以确保我们的模型持续改进，并且有效利用 GPU 资源，避免浪费。"]},{"cell_type":"markdown","id":"65fce60d","metadata":{},"source":["![charts.png](../../figures/charts.png)"]},{"cell_type":"markdown","id":"353ec04d","metadata":{},"source":["| loss0| loss1 \n","|:------:|:------:|\n","| ![loss0](../../figures/loss0.png) | ![loss1](../../figures/loss1.png) |\n"]},{"cell_type":"markdown","id":"73cf53a5","metadata":{"id":"73cf53a5"},"source":["在完成模型训练后，我们将使用该模型生成样本。我们定义了一些 prompt，并使用它们来为我们的角色生成背景故事。接下来，我们创建一个新的表格，用于记录生成的结果。在每个 prompt 上调用 `model.generate` 来生成对应的文本。我们可以在此处传递各种参数，例如 `top_p` 或温度系数（`temperature`），以引导模型生成。生成的结果被添加到表格中，并最终记录在 `wandb` 中。"]},{"cell_type":"code","execution_count":14,"id":"7911e43f-f4ce-4855-9f68-662438af8d24","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"height":336,"id":"7911e43f-f4ce-4855-9f68-662438af8d24","outputId":"e642ca95-4ec7-47e4-c248-dc5ebd4ac9a4"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n"]}],"source":["transformers.logging.set_verbosity_error() # 抑制 tokenizer 警告\n","\n","prefix = \"Generate Backstory based on following information Character Name: \"\n","\n","prompts = [\n","    \"Frogger Character Race: Aarakocra Character Class: Ranger Output: \",\n","    \"Smarty Character Race: Aasimar Character Class: Cleric Output: \",\n","    \"Volcano Character Race: Android Character Class: Paladin Output: \",\n","]\n","\n","table = wandb.Table(columns=[\"prompt\", \"generation\"])\n","# 在每个 prompt 上调用\"model.generate\"来生成对应的文本。\n","for prompt in prompts:\n","    input_ids = tokenizer.encode(prefix + prompt, return_tensors=\"pt\")\n","    output = model.generate(input_ids, do_sample=True, max_new_tokens=50, top_p=0.3)\n","    output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","    table.add_data(prefix + prompt, output_text)\n","\n","wandb.log({'tiny_generations': table})"]},{"cell_type":"markdown","id":"a7caafaf-dfb7-413d-a329-8520aea5f73a","metadata":{"id":"a7caafaf-dfb7-413d-a329-8520aea5f73a"},"source":["**注意**：LLM 并不总是生成相同的结果。您生成的角色和背景故事可能与视频不同。"]},{"cell_type":"code","execution_count":15,"id":"3083c6a3-fdb8-44ab-a028-c0a222a2fdef","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":956,"referenced_widgets":["267e282e0a0f4c4f83a46898804199c4","c87dda5bd52c45ac861bea6cf6d10a7a","79fe43a750624fc5b0c8b524c9bb4fde","c39faa4d0eed4c6b9788bcbe0d73dac4","6af93ffbbf404a5da28e1d7115291083","4002ea385a98418dbfd509c22f520f72","27df8e9973d045e691a18328c6779b3b","1668bbfb2e6d4705987149a9928de48f"]},"height":30,"id":"3083c6a3-fdb8-44ab-a028-c0a222a2fdef","outputId":"5a07bdd1-9ece-40cd-ec05-278fbf2d43b2"},"outputs":[{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"267e282e0a0f4c4f83a46898804199c4","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.003 MB of 0.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.655475…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▃▃▂▃▃▃▂▂▃▃▂▃▂▂▃▃▂▃▂▂▂▂▃▃▂▃▂▂▂▂▁▂▂▁▂▂</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>3.35072</td></tr><tr><td>eval/runtime</td><td>158.3652</td></tr><tr><td>eval/samples_per_second</td><td>2.936</td></tr><tr><td>eval/steps_per_second</td><td>0.373</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>233</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.8045</td></tr><tr><td>train/total_flos</td><td>40423258718208.0</td></tr><tr><td>train/train_loss</td><td>3.74194</td></tr><tr><td>train/train_runtime</td><td>1912.6777</td></tr><tr><td>train/train_samples_per_second</td><td>0.971</td></tr><tr><td>train/train_steps_per_second</td><td>0.122</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">sandy-river-2</strong> at: <a href='https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning/runs/8o77rmiz?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88' target=\"_blank\">https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning/runs/8o77rmiz?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230813_134429-8o77rmiz/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.finish()"]},{"cell_type":"markdown","id":"f0f48e73","metadata":{"id":"f0f48e73"},"source":["我们可以在仪表板中查看 prompt 以及生成的样本。从中可以观察到，这个小模型存在一些问题。这是可以理解的，因为我们在优化速度而不是性能方面进行了调整。从您所提供的消息和输出中，您可以判断模型的表现是否良好。我们鼓励您提出可能与您特定用例相关的指标，并进行实现和记录。例如，您可以测量唯一单词的数量。在第三个 prompt 生成的样本中，我们可以看到它只使用了三个单词，即 `the tribe of`。这可能不是一个很好的输出。\n","\n","因此，在下次训练或微调模型时，我们希望您能够利用这些工具更快地获得更好的结果。"]},{"cell_type":"markdown","id":"dfa3bfcc-2885-4eb8-8a18-a236c69e1a98","metadata":{"height":30,"id":"dfa3bfcc-2885-4eb8-8a18-a236c69e1a98"},"source":["![tiny-generations.png](../../figures/tiny-generations.png)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"008d4419e82f46be82d2a5f50ba1bd86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1668bbfb2e6d4705987149a9928de48f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"267e282e0a0f4c4f83a46898804199c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_c87dda5bd52c45ac861bea6cf6d10a7a","IPY_MODEL_79fe43a750624fc5b0c8b524c9bb4fde"],"layout":"IPY_MODEL_c39faa4d0eed4c6b9788bcbe0d73dac4"}},"2687806020864ec8a02e9c237b168a1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efc62b9109b64216b0e1463c4aad5edf","placeholder":"​","style":"IPY_MODEL_67c75cf288834525a38d4779d9344515","value":"Map: 100%"}},"27df8e9973d045e691a18328c6779b3b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"392a389d2b3e4469a4d97e25905db827":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2687806020864ec8a02e9c237b168a1b","IPY_MODEL_e7b21c44f91d41acbeeb9a5b756de8db","IPY_MODEL_e844acd81ba64610b5a489d678ca83ec"],"layout":"IPY_MODEL_b0e68cd5eef94c87b9d694777f4d4bd6"}},"4002ea385a98418dbfd509c22f520f72":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67c75cf288834525a38d4779d9344515":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6af93ffbbf404a5da28e1d7115291083":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79fe43a750624fc5b0c8b524c9bb4fde":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_27df8e9973d045e691a18328c6779b3b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1668bbfb2e6d4705987149a9928de48f","value":1}},"98928bfce80146d889963509e0d43f88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6768ce6f36740f39bd3866ffb6339fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac69ce5800a44e2e88ac6e0db675f770":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0e68cd5eef94c87b9d694777f4d4bd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c39faa4d0eed4c6b9788bcbe0d73dac4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c87dda5bd52c45ac861bea6cf6d10a7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6af93ffbbf404a5da28e1d7115291083","placeholder":"​","style":"IPY_MODEL_4002ea385a98418dbfd509c22f520f72","value":"0.004 MB of 0.004 MB uploaded (0.000 MB deduped)\r"}},"e7b21c44f91d41acbeeb9a5b756de8db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac69ce5800a44e2e88ac6e0db675f770","max":465,"min":0,"orientation":"horizontal","style":"IPY_MODEL_008d4419e82f46be82d2a5f50ba1bd86","value":465}},"e844acd81ba64610b5a489d678ca83ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6768ce6f36740f39bd3866ffb6339fe","placeholder":"​","style":"IPY_MODEL_98928bfce80146d889963509e0d43f88","value":" 465/465 [00:01&lt;00:00, 432.95 examples/s]"}},"efc62b9109b64216b0e1463c4aad5edf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":5}
