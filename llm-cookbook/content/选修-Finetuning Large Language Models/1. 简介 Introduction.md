# 第一章 简介

**作者 吴恩达教授**

欢迎来到由 Sharon Zhou 讲授的 LLM 微调课程。在我访问不同的研究小组时，经常听到有人问：怎样才能在自己的数据或任务中使用这些 LLM ？你可能已经知道如何为 LLM 创建 prompt，本课程将介绍另一个重要工具：LLM 的微调。

## 一、prompt工程与微调

具体来说，微调就是利用开源 LLM ，并在自己的数据上对其进行进一步训练。虽然编写 prompt 可以很好地让 LLM 遵循指令，执行任务，如提取关键词或将文本分为正面或负面情感。

如果进行微调，就能让 LLM 更稳定地完成你想要的任务。我发现，通过编写prompt 让 LLM 以某种风格说话，比如更乐于助人或更有礼貌，或者在特定程度上简洁而不是啰嗦，也很有挑战性。

微调也是调整 LLM 语气的好方法。人们现在已经意识到 ChatGPT 和其他流行的 LLM 进行大量关于特定主题问答的惊人能力。但是，个人和公司也希望自己的私人和专有数据，也拥有相同的连接和界面。其中一种方法就是使用你的数据训练 LLM。当然，从零开始 LLM 需要海量数据，可能是数千亿甚至超过万亿字的数据，还需要大量 GPU 计算资源。

但通过微调，你可以利用现有的 LLM，并在自己的数据上对其进行进一步训练。

## 二、课程基本内容

但通过微调，你可以利用现有的 LLM，并在自己的数据上对其进行进一步训练。因此，在本课程中，你将了解*什么是*微调、微调何时会对你的*应用*有所帮助、微调如何融入*训练*、微调*与提示词工程或检索增强生成*有何不同、 以及*如何将这些技术与微调技术结合*使用。你还将深入了解微调技术的一种特殊变体，它使 GPT3 成为了 ChatGPT。它被称为指令微调，能让 LLM 遵循指令。

本课程耗费了大量心血。我们要感谢整个 Laminar 团队，特别是设计方面的 Nina Wei，以及deeplearning.ai 的 Tommy Nelson 和 Jeff Lodwig。在大约一个小时左右的时间里，通过这个简短的课程，你将深入了解如何通过在自己的数据上微调现有的 LLM 来构建自己的 LLM。让我们开始吧。
