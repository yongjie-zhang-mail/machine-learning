# 第一章、简介

欢迎来参加由**吴恩达老师和 Cohere 合作伙伴打造的《Large Language Models with Semantic Search》短期课程**。本课程的讲师为 **Jay Allamar 和 Luis Serrano** 。Jay 和 Luis 都是经验丰富的机器学习工程师兼教育者。Jay 是书籍《Hands-On Large Language Models》的合著者。Luis 是《Grokking Machine Learning》的作者，他还曾在 DeepLearning.ai 的《Math for Machine Learning》这门课中进行教授。在 Cohere ，Jay 和 Luis 与 Neil Amir 一起致力于名为 LLMU 的网站，并在教授开发者使用大型语言模型(LLMs) 方面积累了丰富经验。在这门课程中，我们将学习如何将 LLMs 融入到自己应用程序的信息搜索中。例如，假设我们运营一个拥有大量文章的网站，可以想象成类似于维基百科，或者是一个有大量电子商务产品的网站。现在有了 LLMs ，我们可以做得更多。

首先，我们可以让用户提问，然后系统会搜索网站或数据库来回答问题。其次，LLM 还能使检索结果更符合用户提问的意义或语义。

这门课程包括以下几个内容。
1. 我们将学习如何使用基本的关键字检索，也叫做词汇搜索。该算法查找与 query 具有最高匹配词数量的文档。

2. 学习如何使用一种称为 Re-rank 的方法增强关键字检索。顾名思义，这种算法会根据与 query 的相关性对响应进行排名。

3. 学习一种更高级的搜索方法--稠密检索(Dense Retrival)。这种算法尝试使用文本的实际含义或语义含义进行搜索。这种方法会使用到 embeddings ，一种将每段文本映射成为词向量的方法。同时，我们还将从零开始构建一个全新的向量索引。

4. 与其他模型类似，搜索算法需要得到适当的评估。因此，我们还将学习如何有效地进行评估。

5. 由于 LLMs 可以用于生成答案，我们还可以将学习如何将搜索结果插入 LLMs 中，并让其基于这些结果生成答案。通过使用 embeddings 进行稠密检索，极大地提高了 LLMs 的问答能力，因为它首先搜索并检索相关文档，然后根据这些检索到的信息生成答案。

接下来，让我们深入探讨并进入接下来的学习中吧！