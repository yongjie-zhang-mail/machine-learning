{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1c98c44-0505-43b2-957c-86aa4d0e621e",
   "metadata": {
    "id": "a1c98c44-0505-43b2-957c-86aa4d0e621e"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.cn/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3b4e8b-269c-4cc8-8470-1db4a91b6c34",
   "metadata": {
    "id": "1c3b4e8b-269c-4cc8-8470-1db4a91b6c34"
   },
   "source": [
    "<br>\n",
    "\n",
    "# <font color=\"#76b900\">**Notebook 5:** å¤„ç†å¤§å‹æ–‡æ¡£</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "åœ¨ä¸Šä¸€ä¸ª notebook ä¸­ï¼Œæˆ‘ä»¬äº†è§£äº†è¿è¡ŒçŠ¶æ€é“¾å’ŒçŸ¥è¯†åº“ï¼æœ€åï¼Œæˆ‘ä»¬æ‹¥æœ‰äº†æ‰§è¡Œç®€å•å¯¹è¯ç®¡ç†å’Œè‡ªå®šä¹‰çŸ¥è¯†è·Ÿè¸ªæ‰€éœ€çš„æ‰€æœ‰å·¥å…·ã€‚åœ¨æ­¤ notebook ä¸­ï¼Œæˆ‘ä»¬å°†æŠŠç±»ä¼¼çš„æ€è·¯åº”ç”¨åœ¨å¤§å‹æ–‡æ¡£ä¸Šï¼Œçœ‹çœ‹è¿™ä¼šä½¿æˆ‘ä»¬çš„ LLM é‡åˆ°äº›ä»€ä¹ˆé—®é¢˜ã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "### **å­¦ä¹ ç›®æ ‡ï¼š**\n",
    "\n",
    "* ç†Ÿæ‚‰æ–‡æ¡£åŠ è½½å™¨åŠå…¶å®ç”¨åŠŸèƒ½ã€‚\n",
    "* äº†è§£å¦‚ä½•é€šè¿‡å¯¹æ–‡æ¡£è¿›è¡Œåˆ†å—æ¥é€æ¸å»ºç«‹çŸ¥è¯†åº“ï¼Œä»è€Œåœ¨æœ‰é™çš„ä¸Šä¸‹æ–‡ç©ºé—´ä¸­è§£æå¤§å‹æ–‡æ¡£ã€‚\n",
    "* ç†è§£å¦‚ä½•åˆ©ç”¨æ–‡æ¡£å—è¿›è¡Œæ¸è¿›å¼é‡æ„ï¼ˆprogressive recontextualizationï¼‰ã€è½¬æ¢ï¼ˆcoersionï¼‰å’Œæ•´åˆï¼ˆconsolidationï¼‰ï¼Œä»¥åŠå®ƒä»¬çš„å±€é™ã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "### **æ€è€ƒé—®é¢˜ï¼š**\n",
    "\n",
    "* æŸ¥çœ‹ ArxivParser ä¸­çš„æ•°æ®å—ï¼Œæ‚¨ä¼šå‘ç°æœ‰äº›å—æ²¡ä»€ä¹ˆæ„ä¹‰ï¼Œæˆ–è€…åœ¨æ–‡æœ¬è½¬æ¢çš„è¿‡ç¨‹ä¸­è¢«æŸåäº†ã€‚å®ƒæ˜¯å¦ä¼šå¯¹è¿™äº›æ•°æ®å—è¿›è¡Œæ¸…ç†ï¼Ÿ\n",
    "* è€ƒè™‘ä¸€ä¸‹æ–‡æ¡£æ‘˜è¦å·¥ä½œæµï¼ˆæˆ–å…¶å®ƒéœ€è¦å¤„ç†å¤§é‡æ–‡æ¡£å—çš„å·¥ä½œæµï¼‰ï¼Œåº”è¯¥å¤šä¹…æ‰§è¡Œä¸€æ¬¡ï¼Œä»€ä¹ˆæ—¶å€™æ‰§è¡Œåˆç†ï¼Ÿ\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Notebook ç‰ˆæƒå£°æ˜ï¼š**\n",
    "\n",
    "* æœ¬ notebook æ˜¯ [**NVIDIA æ·±åº¦å­¦ä¹ åŸ¹è®­ä¸­å¿ƒ**](https://www.nvidia.cn/training/)çš„è¯¾ç¨‹[**ã€Šæ„å»ºå¤§è¯­è¨€æ¨¡å‹ RAG æ™ºèƒ½ä½“ã€‹**](https://www.nvidia.cn/training/instructor-led-workshops/building-rag-agents-with-llms/)ä¸­çš„ä¸€éƒ¨åˆ†ï¼Œæœªç» NVIDIA æˆæƒä¸å¾—åˆ†å‘ã€‚\n",
    "\n",
    "<br> \n",
    "\n",
    "### **ç¯å¢ƒè®¾ç½®ï¼š**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9214bd93-d65d-4dbd-94e3-254a2f670c52",
   "metadata": {
    "id": "9214bd93-d65d-4dbd-94e3-254a2f670c52"
   },
   "outputs": [],
   "source": [
    "## Necessary for Colab, not necessary for course environment\n",
    "# %pip install -qq langchain langchain-nvidia-ai-endpoints gradio\n",
    "# %pip install -qq arxiv pymupdf\n",
    "\n",
    "# import os\n",
    "# os.environ[\"NVIDIA_API_KEY\"] = \"nvapi-...\"\n",
    "\n",
    "from functools import partial\n",
    "from rich.console import Console\n",
    "from rich.style import Style\n",
    "from rich.theme import Theme\n",
    "\n",
    "console = Console()\n",
    "base_style = Style(color=\"#76B900\", bold=True)\n",
    "pprint = partial(console.print, style=base_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c33c07-19b8-4c81-8d99-30fa2b3b2017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "ChatNVIDIA.get_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8583a1-c10a-41da-8256-49520f868670",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Useful utility method for printing intermediate states\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from functools import partial\n",
    "\n",
    "def RPrint(preface=\"State: \"):\n",
    "    def print_and_return(x, preface=\"\"):\n",
    "        print(f\"{preface}{x}\")\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))\n",
    "\n",
    "def PPrint(preface=\"State: \"):\n",
    "    def print_and_return(x, preface=\"\"):\n",
    "        pprint(preface, x)\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8ac2e-eb68-4b84-85fe-3a6661eba976",
   "metadata": {
    "id": "77c8ac2e-eb68-4b84-85fe-3a6661eba976"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **ç¬¬ 1 éƒ¨åˆ†ï¼š** ä¸æ–‡æ¡£èŠå¤©\n",
    "\n",
    "æ­¤ notebook å°†å¼€å§‹è®¨è®ºç”¨ LLM ä¸æ–‡æ¡£è¿›è¡ŒèŠå¤©ã€‚å½“å‰ï¼Œåœ¨å¤§å‹å…¬å…±æ•°æ®æˆ–ç‰¹å®šæ•°æ®ä¸Šè®­ç»ƒèŠå¤©æ¨¡å‹çš„æˆæœ¬ä»¤äººæœ›è€Œå´æ­¥ï¼Œè€Œè®© LLM ç†è§£ä¸€ç³»åˆ— PDF ç”šè‡³ YouTube è§†é¢‘çš„æƒ³æ³•æ‰“å¼€äº†æ›´å¤šå¯èƒ½æ€§ï¼\n",
    "\n",
    "* **æ‚¨çš„ LLM å¯ä»¥æ‹¥æœ‰ä¸€ä¸ªåŸºäºäººç±»å¯è¯»æ–‡æ¡£æ„å»ºçš„å¯ä¿®æ”¹çŸ¥è¯†åº“ï¼Œ**è¿™æ„å‘³ç€æ‚¨å¯ä»¥ç›´æ¥æ§åˆ¶å®ƒèƒ½è®¿é—®ä»€ä¹ˆæ ·çš„æ•°æ®ï¼Œå¹¶æŒ‡ç¤ºå®ƒä¸å…¶äº¤äº’ã€‚\n",
    "* **æ‚¨çš„ LLM å¯ä»¥ç›´æ¥ä»æ–‡æ¡£é›†ä¸­æ•´ç†å’Œæå–å¼•ç”¨ä¿¡æ¯ã€‚**å€ŸåŠ©å……åˆ†çš„æç¤ºå·¥ç¨‹å’ŒæŒ‡ä»¤éµå¾ªå…ˆéªŒï¼Œæ‚¨å¯ä»¥å¼ºåˆ¶æ¨¡å‹ä»…æ ¹æ®æ‚¨æä¾›çš„ææ–™æ‰§è¡ŒåŠ¨ä½œã€‚\n",
    "* **æ‚¨çš„ LLM ç”šè‡³å¯ä»¥ä¸æ‚¨çš„æ–‡æ¡£è¿›è¡Œäº¤äº’ï¼Œå¿…è¦çš„æ—¶å€™æ‰§è¡Œè‡ªåŠ¨ä¿®æ”¹ã€‚**è¿™ä¸ºè‡ªåŠ¨å†…å®¹ä¼˜åŒ–å’Œåˆæˆå¼€è¾Ÿäº†é“è·¯ï¼Œç¨åå°†æ·±å…¥æ¢è®¨ã€‚\n",
    "\n",
    "æ‚¨å¯ä»¥å°½æƒ…å‘æŒ¥æƒ³è±¡åŠ›ï¼Œæƒ³è±¡æ›´å¤šçš„åº”ç”¨åœºæ™¯ã€‚ä¸‹é¢å°±æ¥çœ‹çœ‹å¦‚ä½•å®ç°è¿™äº›ï¼\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **æœ´ç´ çš„æ–¹æ³•ï¼šå°†æ–‡æ¡£å¡ç»™æ¨¡å‹**\n",
    "\n",
    "å‡è®¾æ‚¨æœ‰ä¸€äº›æ–‡æœ¬æ–‡æ¡£ï¼ˆPDFã€åšå®¢ç­‰ï¼‰ï¼Œå¹¶æƒ³è¦å¯¹æ–‡æ¡£ç›¸å…³å†…å®¹è¿›è¡Œæé—®ã€‚å…¶ä¸­ä¸€ä¸ªå¯ä»¥å°è¯•çš„æ–¹æ³•å°±æ˜¯æŠŠæ–‡æ¡£çš„æŸç§è¡¨ç¤ºä¸€è‚¡è„‘å¡è¿›èŠå¤©æ¨¡å‹ï¼ä»æ–‡æ¡£çš„è§’åº¦æ¥çœ‹ï¼Œè¿™ç§°ä¸º[**æ–‡æ¡£å¡«å……**ï¼ˆdocument stuffingï¼‰](https://python.langchain.com/docs/modules/chains/document/stuff)ã€‚\n",
    "\n",
    "> <img src=\"https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/doc_stuff.png\" width=800px/>\n",
    ">\n",
    "> From [**Stuff | LangChain**ğŸ¦œï¸ğŸ”—](https://python.langchain.com/docs/modules/chains/document/stuff)\n",
    "\n",
    "<br>\n",
    "\n",
    "å¦‚æœæ‚¨çš„æ¨¡å‹è¶³å¤Ÿå¼ºå¤§ä¸”æ–‡æ¡£è¶³å¤ŸçŸ­ï¼Œè¿™ä¸ªæ–¹æ³•å¯èƒ½ä¼šæœ‰ä¸é”™çš„æ•ˆæœï¼Œä½†ä¸åº”è¯¥æœŸå¾…å®ƒä¼šåœ¨æ•´ä¸ªæ–‡æ¡£ä¸­éƒ½è¡¨ç°çš„å¾ˆå¥½ã€‚ç”±äºè®­ç»ƒé™åˆ¶ï¼Œè®¸å¤šç°ä»£ LLM åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶éƒ½ä¼šæœ‰å¾ˆå¤§çš„é—®é¢˜ã€‚è™½ç„¶æ— è®ºæ‚¨ä½¿ç”¨å½“ä»Šçš„å“ªç§å¤§æ¨¡å‹ï¼Œé€€åŒ–å¹¶ä¸ä¼šå¸¦æ¥ç¾éš¾æ€§åæœï¼Œä½†å®ƒå¯èƒ½å¾ˆå¿«å°±æ— æ³•æ­£å¸¸åœ°éµå¾ªæŒ‡ä»¤äº†ã€‚\n",
    "  \n",
    "<br>\n",
    "\n",
    "**æ–‡æ¡£æ¨ç†éœ€è¦è§£å†³çš„å…³é”®é—®é¢˜æ˜¯ï¼š**\n",
    "\n",
    "* å¦‚ä½•å°†æ–‡æ¡£åˆ†å‰²æˆå¯æ¨ç†çš„éƒ¨åˆ†ï¼Ÿ\n",
    "* éšç€æ–‡æ¡£å¤§å°å’Œæ•°é‡çš„å¢åŠ ï¼Œæˆ‘ä»¬å¦‚ä½•é«˜æ•ˆåœ°æŸ¥æ‰¾å’Œè€ƒè™‘è¿™äº›æ–‡æ¡£å—ï¼Ÿ\n",
    "\n",
    "æœ¬è¯¾ç¨‹å°†æ¢ç´¢è§£å†³è¿™äº›é—®é¢˜çš„å‡ ç§æ–¹æ³•ï¼ŒåŒæ—¶ç»§ç»­åŸ¹å…» LLM ç¼–æ’æŠ€èƒ½ã€‚**æœ¬ notebook å°†æœ‰åŠ©äºæ‰©å±•æˆ‘ä»¬ä¹‹å‰çš„è¿è¡Œé“¾æŠ€èƒ½ï¼Œå®ç°æ¸è¿›å¼çš„æ¨ç†ï¼Œè€Œä¸‹ä¸€ä¸ª notebook å°†ä»‹ç»å¤§è§„æ¨¡æ£€ç´¢çš„æ–°æŠ€æœ¯ã€‚**æˆ‘ä»¬å°†ç»§ç»­åˆ©ç”¨å…ˆè¿›çš„å¼€æºå·¥å…·ï¼Œæ¥æ„å»ºæ ‡å‡†ã€å¯é›†æˆçš„è§£å†³æ–¹æ¡ˆã€‚\n",
    "\n",
    "æ–‡æ¡£åŠ è½½æ¡†æ¶æœ‰å¾ˆå¤šé€‰æ‹©ï¼Œæ•´ä¸ªè¯¾ç¨‹ä¸­å°†æ¶‰åŠä¸¤ä¸ªä¸»è¦çš„æ¡†æ¶ï¼š\n",
    "* [**LangChain**](https://python.langchain.com/docs/get_started/introduction) æä¾›äº†ä¸€ä¸ªç®€å•çš„æ¡†æ¶ï¼Œå¯ä»¥é€šè¿‡å¸¸è§„åˆ†å—ç­–ç•¥å°† LLM è¿æ¥åˆ°æ‚¨è‡ªå·±çš„æ•°æ®æºï¼Œå¹¶ä¸åµŒå…¥ï¼ˆembeddingï¼‰æ¡†æ¶/æœåŠ¡ä¸€åŒå·¥ä½œã€‚æ­¤æ¡†æ¶æœ€åˆæ˜¯ä¸ºæ”¯æŒ LLM è€Œå¼€å‘ï¼Œå…¶ä¼˜åŠ¿åœ¨äºé“¾çš„æŠ½è±¡å’Œåè°ƒæ™ºèƒ½ä½“ã€‚\n",
    "* [**LlamaIndex**](https://gpt-index.readthedocs.io/en/stable/) æ˜¯ä¸€ä¸ªæ•°æ®æ¡†æ¶ï¼Œä¾› LLM åº”ç”¨æå–ã€æ„å»ºå’Œè®¿é—®ç§æœ‰æˆ–é¢†åŸŸç‰¹å®šæ•°æ®ã€‚åæ¥ä¹Ÿæ‰©å±•æˆç±»ä¼¼ LangChain çš„é€šç”¨ LLM æ¡†æ¶ï¼Œä½†ç›®å‰å®ƒæœ€æ“…é•¿çš„ä»ç„¶æ˜¯ä¸º LLM å¤„ç†æ–‡æ¡£ï¼Œæ¯•ç«Ÿå®ƒæœ€åˆå°±æ˜¯ä¸ºæ­¤è®¾è®¡çš„ã€‚\n",
    "\n",
    "ååˆ†æ¨èæ‚¨è¯¦ç»†äº†è§£ä¸€ä¸‹ LlamaIndex å’Œ LangChain å„è‡ªçš„ä¼˜åŠ¿ï¼Œé€‰æ‹©æœ€é€‚åˆæ‚¨çš„ã€‚ç”±äº LlamaIndex å¯ä¸ LangChain *ä¸€èµ·*ä½¿ç”¨ï¼Œå› æ­¤ä¸¤ä¸ªæ¡†æ¶çš„åŠŸèƒ½[å¯ä»¥ç»“åˆä½¿ç”¨](https://docs.llamaindex.ai/en/stable/community/integrations/using_with_langchain.html)ã€‚ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬å°†åœ¨æœ¬è¯¾ç¨‹ä¸­ä¸€ç›´ç”¨ LangChainï¼Œå¯¹ LlamaIndex æ„Ÿå…´è¶£çš„å­¦å‘˜å¯ä»¥é€šè¿‡ [**NVIDIA/GenerativeAIExamples ä»£ç åº“**](https://github.com/NVIDIA/GenerativeAIExamples/tree/main/RetrievalAugmentedGeneration/notebooks)è¿›ä¸€æ­¥æ¢ç´¢ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3310462b-f215-4d00-9d59-e613921bed0a",
   "metadata": {
    "id": "3310462b-f215-4d00-9d59-e613921bed0a"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **ç¬¬ 2 éƒ¨åˆ†ï¼š** åŠ è½½æ–‡æ¡£\n",
    "\n",
    "LangChain æä¾›äº†å„ç§[æ–‡æ¡£åŠ è½½å™¨](https://python.langchain.com/docs/integrations/document_loaders)ä»¥ä»ä¸åŒçš„æ¥æºå’Œä½ç½®ï¼ˆæœ¬åœ°å­˜å‚¨ã€ç§æœ‰ s3 å­˜å‚¨æ¡¶ã€å…¬å…±ç½‘ç«™ã€æ¶ˆæ¯ API ç­‰ï¼‰è¯»å–å„ç§æ–‡æ¡£ï¼ˆHTMLã€PDFã€ä»£ç ï¼‰ã€‚è¿™äº›åŠ è½½ç¨‹åºä¼šæŸ¥è¯¢æ‚¨çš„æ•°æ®æºå¹¶è¿”å›åŒ…å«å†…å®¹å’Œå…ƒæ•°æ®çš„ `Document` å¯¹è±¡ï¼Œé€šå¸¸æ˜¯çº¯æ–‡æœ¬æˆ–äººç±»å¯è¯»çš„æ ¼å¼ã€‚æœ‰è®¸å¤šå¯ç”¨çš„æ–‡æ¡£åŠ è½½ç¨‹åºï¼Œ[è¿™é‡Œ](https://python.langchain.com/docs/integrations/document_loaders)åˆ—å‡ºäº† LangChain çš„å‡ ä¸ªç¬¬ä¸€æ–¹é€‰é¡¹ã€‚\n",
    "\n",
    "**åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ LangChain çš„åŠ è½½å™¨ä¹‹ä¸€åŠ è½½ç ”ç©¶è®ºæ–‡ï¼š**\n",
    "* [`UnstructuredFileLoader`](https://python.langchain.com/docs/integrations/document_loaders/unstructured_file)ï¼šé€‚ç”¨äºä»»æ„æ–‡ä»¶çš„æ–‡æ¡£åŠ è½½å™¨ï¼Œä¸ä¼šå¯¹æ–‡æ¡£ç»“æ„åšå¤ªå¤šå‡è®¾ï¼Œé€šå¸¸å¤Ÿç”¨äº†ã€‚\n",
    "* [`ArxivLoader`](https://python.langchain.com/docs/integrations/document_loaders/arxiv)ï¼šä¸€ä¸ªæ›´ä¸“ä¸šçš„æ–‡ä»¶åŠ è½½ç¨‹åºï¼Œå¯ä»¥ç›´æ¥ä¸ Arxiv æ¥å£é€šä¿¡ã€‚[ä»…ä¸¾ä¸€ä¸ªä¾‹å­](https://python.langchain.com/docs/integrations/document_loaders)ï¼Œè¿™å°†å¯¹æ•°æ®åšå‡ºæ›´å¤šå‡è®¾ï¼Œä»¥ç”Ÿæˆæ›´å¥½çš„è§£æå¹¶è‡ªåŠ¨å¡«å……å…ƒæ•°æ®ï¼ˆå½“æ‚¨æœ‰å¤šç§æ–‡æ¡£/æ ¼å¼æ—¶å¾ˆæœ‰ç”¨ï¼‰ã€‚\n",
    "\n",
    "æˆ‘ä»¬çš„ä»£ç ç¤ºä¾‹ä¼šé»˜è®¤ä½¿ç”¨ `ArxivLoader` æ¥åŠ è½½ [MRKL](https://arxiv.org/abs/2205.00445) æˆ– [ReAct](https://arxiv.org/abs/2210.03629) æ–‡ç« ï¼Œæ‚¨å¾ˆæœ‰å¯èƒ½åœ¨ç»§ç»­ç ”ç©¶èŠå¤©æ¨¡å‹çš„æŸä¸ªé˜¶æ®µè¯»åˆ°è¿™äº›è®ºæ–‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4382b61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3944,
     "status": "ok",
     "timestamp": 1703112979370,
     "user": {
      "displayName": "Vadim Kudlay",
      "userId": "00553664172613290122"
     },
     "user_tz": 360
    },
    "id": "b4382b61",
    "outputId": "d6e95b9b-97be-4984-a9fd-58a528091146"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.document_loaders import ArxivLoader\n",
    "\n",
    "## Loading in the file\n",
    "\n",
    "## Unstructured File Loader: Good for arbitrary \"probably good enough\" loader\n",
    "# documents = UnstructuredFileLoader(\"llama2_paper.pdf\").load()\n",
    "\n",
    "## More specialized loader, won't work for everything, but simple API and usually better results\n",
    "documents = ArxivLoader(query=\"2404.16130\").load()  ## GraphRAG\n",
    "# documents = ArxivLoader(query=\"2404.03622\").load()  ## Visualization-of-Thought\n",
    "# documents = ArxivLoader(query=\"2404.19756\").load()  ## KAN: Kolmogorov-Arnold Networks\n",
    "# documents = ArxivLoader(query=\"2404.07143\").load()  ## Infini-Attention\n",
    "# documents = ArxivLoader(query=\"2210.03629\").load()  ## ReAct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hw0SL--6cirp",
   "metadata": {
    "id": "hw0SL--6cirp"
   },
   "source": [
    "<br>\n",
    "\n",
    "ä»å¯¼å…¥ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ­¤è¿æ¥å™¨ï¼ˆconnectorï¼‰å…è®¸æˆ‘ä»¬è®¿é—®ä¸¤ä¸ªä¸åŒçš„ç»„ä»¶ï¼š\n",
    "* `page_content` å®é™…ä¸Šå°±æ˜¯äººç±»å¯è¯»æ ¼å¼çš„æ–‡æ¡£æ­£æ–‡ã€‚\n",
    "* `metadata` æ˜¯è¿æ¥å™¨é€šè¿‡å…¶æ•°æ®æºæä¾›çš„æ–‡æ¡£ç›¸å…³ä¿¡æ¯ã€‚\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬å°±æ¥çœ‹çœ‹æ–‡æ¡£æ­£æ–‡ä¸­éƒ½åŒ…æ‹¬ä»€ä¹ˆï¼Œæ‚¨å¯èƒ½ä¼šæ³¨æ„åˆ°æ–‡æ¡£çš„é•¿åº¦æœ‰ç‚¹ä¸å—æ§åˆ¶äº†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2289d525-2c2b-4a99-9a48-00f9b951ae02",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1703113455184,
     "user": {
      "displayName": "Vadim Kudlay",
      "userId": "00553664172613290122"
     },
     "user_tz": 360
    },
    "id": "2289d525-2c2b-4a99-9a48-00f9b951ae02",
    "outputId": "98b9ef68-c36b-478f-9bbb-1e45b2c49d60"
   },
   "outputs": [],
   "source": [
    "## Printing out a sample of the content\n",
    "print(\"Number of Documents Retrieved:\", len(documents))\n",
    "print(f\"Sample of Document 1 Content (Total Length: {len(documents[0].page_content)}):\")\n",
    "print(documents[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1JjUK2ZSd0HL",
   "metadata": {
    "id": "1JjUK2ZSd0HL"
   },
   "source": [
    "<br>  \n",
    "\n",
    "ç›¸æ¯”ä¹‹ä¸‹ï¼Œå…ƒæ•°æ®çš„å¤§å°æ›´ç²¾ç®€ï¼Œè¶³å¤Ÿä½œä¸ºæ‚¨çš„èŠå¤©æ¨¡å‹çš„ä¸Šä¸‹æ–‡ç»„ä»¶äº†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Py2lbRXlcX81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1703112982386,
     "user": {
      "displayName": "Vadim Kudlay",
      "userId": "00553664172613290122"
     },
     "user_tz": 360
    },
    "id": "Py2lbRXlcX81",
    "outputId": "07197dd4-1609-4ecf-ae54-cf6ef3d25458"
   },
   "outputs": [],
   "source": [
    "pprint(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7046ea74-0b81-400e-8364-449f421d2add",
   "metadata": {
    "id": "7046ea74-0b81-400e-8364-449f421d2add"
   },
   "source": [
    "<br>  \n",
    "\n",
    "å°½ç®¡æŒ‰åŸæ ·ä¿ç•™å…ƒæ•°æ®æ ¼å¼å¹¶å®Œå…¨å¿½ç•¥æ­£æ–‡å¬èµ·æ¥å¥½åƒå¾ˆæœ‰å¸å¼•åŠ›ï¼Œä½†å¦‚æœä¸æ·±å…¥å®Œæ•´æ–‡æœ¬ï¼Œå°±æ— æ³•è·å–ä¸€äº›å…³é”®ç‰¹å¾ï¼š\n",
    "* **ä¸ä¸€å®šä¿è¯æœ‰å…ƒæ•°æ®ã€‚**å¯¹äº `arxiv`ï¼Œè®ºæ–‡æ‘˜è¦ã€æ ‡é¢˜ã€ä½œè€…å’Œæ—¥æœŸæ˜¯æäº¤æ–‡ç« æ‰€å¿…é¡»åŒ…å«çš„ä¿¡æ¯ï¼Œå› æ­¤èƒ½æŸ¥åˆ°å®ƒä»¬å¹¶ä¸ç¨€å¥‡ã€‚ä½†å¯¹äºä»»æ„çš„ä¸€ä¸ª PDF æˆ–ç½‘é¡µï¼Œæƒ…å†µå°±ä¸ä¸€å®šäº†ã€‚\n",
    "* **æ™ºèƒ½ä½“å°†æ— æ³•æ›´æ·±å…¥åœ°äº†è§£æ–‡æ¡£å†…å®¹ã€‚**æ‘˜è¦æ–¹ä¾¿æˆ‘ä»¬äº†è§£ä¿¡æ¯ï¼Œå¯ä»¥æŒ‰åŸæ ·ä¿ç•™ï¼Œä½†å®ƒå¹¶ä¸æä¾›ä¸æ­£æ–‡è¿›è¡Œä»»æ„äº¤äº’çš„èƒ½åŠ›ã€‚\n",
    "* **æ™ºèƒ½ä½“ä»ç„¶æ— æ³•åŒæ—¶æ¨ç†å¤ªå¤šæ–‡æ¡£ã€‚**ä¹Ÿè®¸åœ¨ MRKL/ReAct ç¤ºä¾‹ä¸­ï¼Œæ‚¨å¯ä»¥å°†è¿™ä¸¤ä¸ªæ‘˜è¦åˆå¹¶åˆ°ä¸€ä¸ªä¸Šä¸‹æ–‡ä¸­æé—®ã€‚é‚£å½“æ‚¨éœ€è¦åŒæ—¶ä¸ 5 ä¸ªæ–‡æ¡£è¿›è¡Œäº¤äº’æ—¶æ€ä¹ˆåŠå‘¢ï¼Ÿæ•´ä¸ªç›®å½•å‘¢ï¼Ÿæ‚¨å¾ˆå¿«å°±ä¼šå‘ç°ï¼Œå“ªæ€•åªæ˜¯æ€»ç»“å’Œåˆ—å‡ºè¿™äº›æ–‡æ¡£ï¼Œéƒ½ä¼šä½¿ä¸Šä¸‹æ–‡çª—å£ä¿¡æ¯è¶…è½½ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0449e4",
   "metadata": {
    "id": "4e0449e4"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **ç¬¬ 3 éƒ¨åˆ†** è½¬æ¢æ–‡æ¡£\n",
    "\n",
    "æ–‡æ¡£åŠ è½½å®Œæˆåï¼Œè¦æ˜¯æˆ‘ä»¬æƒ³æŠŠå®ƒä½œä¸ºä¸Šä¸‹æ–‡ä¼ ç»™ LLMï¼Œé€šå¸¸è¦å…ˆåšä¸€æ­¥è½¬æ¢ã€‚ä¸€ç§è½¬æ¢æ–¹æ³•æ˜¯**åˆ†å—**ï¼ˆchunkingï¼‰ï¼Œå®ƒæŠŠå¤§æ®µçš„å†…å®¹åˆ†è§£æˆå°æ®µã€‚è¿™ç§æŠ€å·§å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºå®ƒèƒ½[ä¼˜åŒ–ä»å‘é‡æ•°æ®åº“è¿”å›å†…å®¹çš„ç›¸å…³æ€§](https://www.pinecone.io/learn/chunking-strategies/)ã€‚\n",
    "\n",
    "LangChain æä¾›äº†[å„ç§æ–‡æ¡£è½¬æ¢å™¨](https://python.langchain.com/docs/integrations/document_transformers/)ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [`RecursiveCharacterTextSplitter`](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter)ã€‚å®ƒå°†å¸®æˆ‘ä»¬éµå¾ªä¸€äº›è‡ªç„¶çš„åœæ­¢ç‚¹æ¥åˆ†å‰²æ–‡æ¡£ï¼ˆè¶Šå¤šè¶Šå¥½ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f564ee4-262e-4721-bf6b-ee8ebdb7a1ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1703112527056,
     "user": {
      "displayName": "Vadim Kudlay",
      "userId": "00553664172613290122"
     },
     "user_tz": 360
    },
    "id": "6f564ee4-262e-4721-bf6b-ee8ebdb7a1ba",
    "outputId": "a4e666e5-5a5c-413b-f5a4-acca742d80d8"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \";\", \",\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "## Some nice custom preprocessing\n",
    "# documents[0].page_content = documents[0].page_content.replace(\". .\", \"\")\n",
    "docs_split = text_splitter.split_documents(documents)\n",
    "\n",
    "# def include_doc(doc):\n",
    "#     ## Some chunks will be overburdened with useless numerical data, so we'll filter it out\n",
    "#     string = doc.page_content\n",
    "#     if len([l for l in string if l.isalpha()]) < (len(string)//2):\n",
    "#         return False\n",
    "#     return True\n",
    "\n",
    "# docs_split = [doc for doc in docs_split if include_doc(doc)]\n",
    "print(len(docs_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8bcc89-c781-44d0-9ec1-1fe45eec8b46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1703112530925,
     "user": {
      "displayName": "Vadim Kudlay",
      "userId": "00553664172613290122"
     },
     "user_tz": 360
    },
    "id": "1f8bcc89-c781-44d0-9ec1-1fe45eec8b46",
    "outputId": "1cf24605-65bb-40a2-e7aa-e2d9a8fb6382"
   },
   "outputs": [],
   "source": [
    "for i in (0, 1, 2, 15, -1):\n",
    "    pprint(f\"[Document {i}]\")\n",
    "    print(docs_split[i].page_content)\n",
    "    pprint(\"=\"*64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e2f969-72cd-4d0e-a150-e3efafc1cdfc",
   "metadata": {
    "id": "57e2f969-72cd-4d0e-a150-e3efafc1cdfc"
   },
   "source": [
    "<br>  \n",
    "\n",
    "æˆ‘ä»¬ç°åœ¨ç”¨çš„çš„åˆ†å—æ–¹æ³•å¾ˆæœ´ç´ ï¼Œä½†è‡³å°‘èƒ½çœ‹å‡ºæ¥æˆ‘ä»¬å¯ä»¥è½»æ¾åœ°è®©åº”ç”¨è·‘èµ·æ¥ã€‚æˆ‘ä»¬ä¸ºå¾—åˆ°è¾ƒå°çš„åˆ†å—åšäº†ä¸€äº›åŠªåŠ›ï¼Œä»¥ä¾¿æ¨¡å‹èƒ½æœ‰æ•ˆåœ°å°†å…¶ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œä½†æˆ‘ä»¬è¦æ€ä¹ˆæŠŠè¿™äº›å—ç”¨äºæ¨ç†å‘¢ï¼Ÿ\n",
    "\n",
    "**åœ¨é’ˆå¯¹ä¸€ç»„ä»»æ„æ–‡æ¡£æ‰©å±•å’Œä¼˜åŒ–æ­¤æ–¹æ³•æ—¶ï¼Œå¯ä»¥å€Ÿé‰´ä»¥ä¸‹åšæ³•ï¼š**\n",
    "\n",
    "* è¯†åˆ«é€»è¾‘ä¸­æ–­çš„æŠ€æœ¯ï¼Œä»¥åŠåˆæˆæ–‡æœ¬çš„æŠ€æœ¯ï¼ˆæ‰‹åŠ¨ã€è‡ªåŠ¨ã€æˆ–è€… LLM è¾…åŠ©ï¼‰ã€‚\n",
    "* æ„å»ºä¿¡æ¯ä¸°å¯Œä¸”ç‹¬ç‰¹çš„æ•°æ®å—ï¼Œé¿å…å†—ä½™ï¼Œä»è€Œæœ€å¤§é™åº¦æé«˜æ•°æ®åº“æ•ˆç”¨ã€‚\n",
    "* è‡ªå®šä¹‰åˆ†å—ä»¥é€‚åº”æ–‡æ¡£çš„ç‰¹æ€§ï¼Œç¡®ä¿åˆ†å—ä¸ä¸Šä¸‹æ–‡ç›¸å…³ä¸”ä¸€è‡´ã€‚\n",
    "* åœ¨æ¯ä¸ªæ•°æ®å—ä¸­éƒ½æ”¾å…¥å…³é”®æ¦‚å¿µã€å…³é”®è¯æˆ–å…ƒæ•°æ®ç‰‡æ®µï¼Œä»¥æé«˜æ•°æ®åº“çš„å¯æœç´¢æ€§å’Œç›¸å…³æ€§ã€‚\n",
    "* æŒç»­è¯„ä¼°åˆ†å—æ•ˆæœï¼Œå¹¶éšæ—¶å‡†å¤‡è°ƒæ•´ç­–ç•¥ï¼Œä»¥åœ¨åˆ†å—å¤§å°å’Œå†…å®¹ä¸°å¯Œåº¦é—´å–å¾—æœ€ä½³å¹³è¡¡ã€‚\n",
    "* è€ƒè™‘ä½¿ç”¨å±‚çº§ç»“æ„ï¼ˆéšå¼ç”Ÿæˆæˆ–æ˜ç¡®æŒ‡å®šï¼‰æ¥æ”¹è¿›æ£€ç´¢ã€‚\n",
    "\t+ å¦‚æœæ‚¨æœ‰å…´è¶£ï¼Œå¯ä»¥æŸ¥çœ‹[ç´¢å¼•æŒ‡å—ä¸­çš„ LlamaIndex æ ‘ç»“æ„](https://docs.llamaindex.ai/en/stable/module_guides/indexing/index_guide.html#tree-index)ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-0QApYgNbyJD",
   "metadata": {
    "id": "-0QApYgNbyJD"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **ç¬¬ 4 éƒ¨åˆ†ï¼š[ç»ƒä¹ ]** é‡æ„æ‘˜è¦ï¼ˆRefining Summariesï¼‰\n",
    "\n",
    "ä¸ºäº†è‡ªåŠ¨æ¨ç†å¤§é‡æ–‡æ¡£ï¼Œä¸€ä¸ªå¯èƒ½çš„æƒ³æ³•æ˜¯ç”¨ LLM åˆ›å»ºä¸€ä¸ªå‹ç¼©çš„æ‘˜è¦æˆ–çŸ¥è¯†åº“ã€‚ä¸æˆ‘ä»¬åœ¨ä¸Šä¸€ä¸ª notebook ä¸­é€šè¿‡å¡«å……æ§½ä½æ¥ç»´æŠ¤å¯¹è¯å†å²è®°å½•ç±»ä¼¼ï¼Œä¿æŒæ•´ä¸ªæ–‡æ¡£çš„å†å²è®°å½•ä¼šæœ‰ä»€ä¹ˆé—®é¢˜ä¹ˆï¼Ÿ\n",
    "\n",
    "æœ¬èŠ‚æˆ‘ä»¬å°†é‡ç‚¹ä»‹ç»ä¸€ä¸ªä»¤äººå…´å¥‹çš„ LLM åº”ç”¨ï¼š**å¤§è§„æ¨¡è‡ªåŠ¨é‡æ„ï¼ˆrefineï¼‰ã€è½¬æ¢ï¼ˆcoerceï¼‰å’Œæ•´åˆï¼ˆconsolidateï¼‰æ•°æ®**ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†å®ç°ä¸€ä¸ªç®€å•ä½†å®ç”¨çš„è¿è¡Œæ—¶ï¼Œç”¨ while å¾ªç¯å’Œè¿è¡ŒçŠ¶æ€é“¾æœºåˆ¶æ¥æ€»ç»“ä¸€ç³»åˆ—æ–‡æ¡£å—ã€‚è¿™ä¸ªè¿‡ç¨‹é€šå¸¸è¢«ç§°ä¸º[**â€œæ–‡æ¡£é‡æ„â€**](https://python.langchain.com/docs/modules/chains/document/refine)ï¼Œå¾ˆå¤§ç¨‹åº¦ä¸Šç±»ä¼¼äºæˆ‘ä»¬ä¹‹å‰çš„å¯¹è¯å¡«æ§½ç»ƒä¹ ã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯æˆ‘ä»¬ç°åœ¨å¤„ç†çš„æ˜¯å¤§å‹æ–‡æ¡£ï¼Œè€Œä¸æ˜¯è¿›è¡Œä¸­çš„èŠå¤©è®°å½•ã€‚\n",
    "\n",
    "> <img src=\"https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/doc_refine.png\" width=1000px/>\n",
    ">\n",
    "> From [**Refine | LangChain**ğŸ¦œï¸ğŸ”—](https://python.langchain.com/docs/modules/chains/document/refine)\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **DocumentSummaryBase æ¨¡å‹**\n",
    "\n",
    "å°±åƒä¸Šä¸€ä¸ª notebook çš„ `KnowledgeBase` ç±»ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ª `DocumentSummaryBase` ç»“æ„æ¥å°è£…æ–‡æ¡£ã€‚ä¸‹é¢çš„ä¾‹å­å°±å°†ç”¨ `running_summary` å­—æ®µæ¥æŸ¥è¯¢æ¨¡å‹ä»¥è·å¾—æœ€ç»ˆæ‘˜è¦ï¼ŒåŒæ—¶ç”¨ `main_ideas` å’Œ `loose_ends` å­—æ®µæ¥é˜²æ­¢æ‘˜è¦æ¼”è¿›è¿‡å¿«ã€‚æˆ‘ä»¬éœ€è¦é€šè¿‡æç¤ºå·¥ç¨‹æ¥ä¿è¯è¿™ä¸€ç‚¹ï¼Œå› æ­¤ç”¨åˆ°äº† `summary_prompt`ã€‚æ‚¨å¯ä»¥æ ¹æ®éœ€è¦å¯¹å…¶è¿›è¡Œä¿®æ”¹ï¼Œä»¥é€‚ç”¨äºæ‚¨çš„æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gE8y2JvLvZ5T",
   "metadata": {
    "id": "gE8y2JvLvZ5T"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables.passthrough import RunnableAssign\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "class DocumentSummaryBase(BaseModel):\n",
    "    running_summary: str = Field(\"\", description=\"Running description of the document. Do not override; only update!\")\n",
    "    main_ideas: List[str] = Field([], description=\"Most important information from the document (max 3)\")\n",
    "    loose_ends: List[str] = Field([], description=\"Open questions that would be good to incorporate into summary, but that are yet unknown (max 3)\")\n",
    "\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are generating a running summary of the document. Make it readable by a technical user.\"\n",
    "    \" After this, the old knowledge base will be replaced by the new one. Make sure a reader can still understand everything.\"\n",
    "    \" Keep it short, but as dense and useful as possible! The information should flow from chunk to (loose ends or main ideas) to running_summary.\"\n",
    "    \" The updated knowledge base keep all of the information from running_summary here: {info_base}.\"\n",
    "    \"\\n\\n{format_instructions}. Follow the format precisely, including quotations and commas\"\n",
    "    \"\\n\\nWithout losing any of the info, update the knowledge base with the following: {input}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7LkjfpOAvlEd",
   "metadata": {
    "id": "7LkjfpOAvlEd"
   },
   "source": [
    "<br>  \n",
    "\n",
    "ç°åœ¨æ­£å¥½å¯ä»¥ç”¨ä¸Šå‰ä¸€ä¸ª notebook çš„ `RExtract` å‡½æ•°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "khRhVghHxBaz",
   "metadata": {
    "id": "khRhVghHxBaz"
   },
   "outputs": [],
   "source": [
    "def RExtract(pydantic_class, llm, prompt):\n",
    "    '''\n",
    "    Runnable Extraction module\n",
    "    Returns a knowledge dictionary populated by slot-filling extraction\n",
    "    '''\n",
    "    parser = PydanticOutputParser(pydantic_object=pydantic_class)\n",
    "    instruct_merge = RunnableAssign({'format_instructions' : lambda x: parser.get_format_instructions()})\n",
    "    def preparse(string):\n",
    "        if '{' not in string: string = '{' + string\n",
    "        if '}' not in string: string = string + '}'\n",
    "        string = (string\n",
    "            .replace(\"\\\\_\", \"_\")\n",
    "            .replace(\"\\n\", \" \")\n",
    "            .replace(\"\\]\", \"]\")\n",
    "            .replace(\"\\[\", \"[\")\n",
    "        )\n",
    "        # print(string)  ## Good for diagnostics\n",
    "        return string\n",
    "    return instruct_merge | prompt | llm | preparse | parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oFtME_s4PRoW",
   "metadata": {
    "id": "oFtME_s4PRoW"
   },
   "source": [
    "<br>\n",
    "\n",
    "è®°ä½ï¼Œä»¥ä¸‹ä»£ç ä¼šåœ¨ for å¾ªç¯ä¸­è°ƒç”¨æ­£åœ¨è¿è¡Œçš„çŠ¶æ€é“¾æ¥è¿­ä»£æ–‡æ¡£ï¼å”¯ä¸€éœ€è¦å®ç°çš„æ˜¯ `parse_chain`ï¼Œå®ƒéœ€è¦èƒ½å¤Ÿå°†çŠ¶æ€æ­£ç¡®åœ°ä¼ é€’åˆ° `RExtract`ã€‚ä¹‹åï¼Œç³»ç»Ÿåº”èƒ½æ­£å¸¸å·¥ä½œï¼ŒåŠ¨æ€åœ°ç»´æŠ¤æ–‡æ¡£æ‘˜è¦ï¼ˆé’ˆå¯¹ä½¿ç”¨çš„æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´æç¤ºè¯ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6sODIfHUgz6m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79192,
     "status": "ok",
     "timestamp": 1703112894722,
     "user": {
      "displayName": "Vadim Kudlay",
      "userId": "00553664172613290122"
     },
     "user_tz": 360
    },
    "id": "6sODIfHUgz6m",
    "outputId": "7b5aee70-078b-458e-d2a7-e8601b789fb1"
   },
   "outputs": [],
   "source": [
    "latest_summary = \"\"\n",
    "\n",
    "## TODO: Use the techniques from the previous notebook to complete the exercise\n",
    "def RSummarizer(knowledge, llm, prompt, verbose=False):\n",
    "    '''\n",
    "    Exercise: Create a chain that summarizes\n",
    "    '''\n",
    "    ###########################################################################################\n",
    "    ## START TODO:\n",
    "\n",
    "    def summarize_docs(docs):        \n",
    "        ## TODO: Initialize the parse_chain appropriately; should include an RExtract instance.\n",
    "        ## HINT: You can get a class using the <object>.__class__ attribute...\n",
    "        parse_chain = RunnableAssign({'info_base' : (lambda x: None)})\n",
    "        ## TODO: Initialize a valid starting state. Should be similar to notebook 4\n",
    "        state = {}\n",
    "\n",
    "        global latest_summary  ## If your loop crashes, you can check out the latest_summary\n",
    "        \n",
    "        for i, doc in enumerate(docs):\n",
    "            ## TODO: Update the state as appropriate using your parse_chain component\n",
    "\n",
    "            assert 'info_base' in state \n",
    "            if verbose:\n",
    "                print(f\"Considered {i+1} documents\")\n",
    "                pprint(state['info_base'])\n",
    "                latest_summary = state['info_base']\n",
    "                clear_output(wait=True)\n",
    "\n",
    "        return state['info_base']\n",
    "        \n",
    "    ## END TODO\n",
    "    ###########################################################################################\n",
    "    \n",
    "    return RunnableLambda(summarize_docs)\n",
    "\n",
    "# instruct_model = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\").bind(max_tokens=4096)\n",
    "instruct_model = ChatNVIDIA(model=\"mistralai/mixtral-8x22b-instruct-v0.1\").bind(max_tokens=4096)\n",
    "instruct_llm = instruct_model | StrOutputParser()\n",
    "\n",
    "## Take the first 10 document chunks and accumulate a DocumentSummaryBase\n",
    "summarizer = RSummarizer(DocumentSummaryBase(), instruct_llm, summary_prompt, verbose=True)\n",
    "summary = summarizer.invoke(docs_split[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eb5710-23f7-4782-84eb-1fc8f73500b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(latest_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tKtoLf6DPv4Z",
   "metadata": {
    "id": "tKtoLf6DPv4Z"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **ç¬¬ 5 éƒ¨åˆ†ï¼š** å¤„ç†åˆæˆæ•°æ®\n",
    "\n",
    "åœ¨ç»“æŸå¯¹ä½¿ç”¨ LLM åšæ–‡æ¡£æ‘˜è¦çš„æ¢ç´¢ä¹‹å‰ï¼Œå€¼å¾—èŠ±ç‚¹æ—¶é—´æ¢è®¨ä¸€ä¸‹æ›´å¹¿çš„åœºæ™¯å’Œæ½œåœ¨æŒ‘æˆ˜ã€‚æˆ‘ä»¬å·²ç»å±•ç¤ºäº†ä¸€ç§èƒ½æå–å‡ºç®€æ´ã€æœ‰æ„ä¹‰æ‘˜è¦çš„æ–¹æ³•ï¼Œç°åœ¨è€ƒè™‘ä¸€ä¸‹ä¸ºä»€ä¹ˆè¿™æ˜¯ä¸ªè‡³å…³é‡è¦çš„æ–¹æ³•ï¼Œä»¥åŠå…¶ä¸­æ¶‰åŠçš„å¤æ‚æ€§ã€‚\n",
    "\n",
    "#### **æ³›åŒ–é‡æ„**\n",
    "\n",
    "éœ€è¦æ³¨æ„ï¼Œè¿™ç§â€œæ¸è¿›å¼æ€»ç»“â€æŠ€æœ¯åªæ˜¯ä¸€ç§å…¥é—¨çº§é“¾ï¼Œå¯¹åˆå§‹æ•°æ®å’Œæ‰€éœ€çš„è¾“å‡ºæ ¼å¼å‡ ä¹ä¸åšå‡è®¾ã€‚ç›¸åŒçš„æŠ€æœ¯å¯ä»¥æ³›åŒ–åˆ°ç”¨æ¥ç”ŸæˆåŒ…å«å·²çŸ¥å…ƒæ•°æ®ã€å­˜åœ¨å¤§é‡å‡è®¾å’Œä¸‹æ¸¸ç›®æ ‡çš„åˆæˆå†…å®¹ä¸Šã€‚\n",
    "\n",
    "**è€ƒè™‘ä»¥ä¸‹æ½œåœ¨åº”ç”¨ï¼š**\n",
    "\n",
    "1. **èšåˆæ•°æ®**ï¼ˆAggregating Dataï¼‰ï¼šæ„å»ºä¸€ç§ç»“æ„ï¼Œå°†åŸå§‹æ•°æ®ä»æ–‡æ¡£å—è½¬æ¢ä¸ºä¸€è‡´ã€æœ‰ç”¨çš„æ‘˜è¦ã€‚\n",
    "2. **åˆ†ç±»å’Œå­ä¸»é¢˜åˆ†æ**ï¼šåˆ›å»ºä¸€ä¸ªç³»ç»Ÿï¼Œå°†æ´å¯Ÿä»æ•°æ®å—æç‚¼åˆ°é¢„å®šçš„ç±»åˆ«ä¸­ï¼Œå¹¶è·Ÿè¸ªå…¶ä¸­æ–°å‡ºç°çš„å­ä¸»é¢˜ã€‚\n",
    "3. **æ•´åˆä¸ºå¯†é›†ä¿¡æ¯å—**ï¼šä¼˜åŒ–è¿™äº›ç»“æ„ï¼Œå°†æ´å¯Ÿæç‚¼ä¸ºç´§å‡‘çš„æ®µï¼Œé€šè¿‡ç›´æ¥å¼•ç”¨è¿›è¡Œæ›´æ·±å…¥çš„åˆ†æã€‚\n",
    "\n",
    "è¿™äº›åº”ç”¨éƒ½é¢„ç¤ºéœ€è¦åˆ›å»ºä¸€ä¸ªèŠå¤©æ¨¡å‹èƒ½è®¿é—®çš„**ç‰¹å®šé¢†åŸŸçŸ¥è¯†å›¾è°±**ã€‚å·²ç»æœ‰ä¸€äº›åº”ç”¨å¯ä»¥è‡ªåŠ¨åŒ–åœ°ç”Ÿæˆå›¾è°±äº†ï¼Œæ¯”å¦‚ [**LangChain çŸ¥è¯†å›¾è°±**](https://python.langchain.com/docs/modules/memory/types/kg)ã€‚è™½ç„¶æ‚¨å¯èƒ½éœ€è¦å¼€å‘å±‚æ¬¡åŒ–çš„ï¼ˆhierachicalï¼‰ç»“æ„å’Œå·¥å…·æ¥æ„å»ºå’Œéå†è¿™ç§ç»“æ„ï¼Œä½†å¦‚æœèƒ½ä¸ºæ‚¨çš„åœºæ™¯æ„å»ºå‡ºä¸€ä¸ªå¥½ç”¨çš„çŸ¥è¯†å›¾è°±ï¼Œé‚£ä¸€ç‚¹éƒ½ä¸äºï¼å¯¹é‚£äº›æœ‰å…´è¶£æ„å»ºé«˜çº§çŸ¥è¯†å›¾è°±ï¼ˆä¾èµ–æ›´åºå¤§ç³»ç»Ÿå’Œå‘é‡ç›¸ä¼¼æ€§ï¼‰çš„å­¦å‘˜ï¼Œæˆ‘ä»¬å‘ç° [**LangChain x Neo4j æ–‡ç« **](https://blog.langchain.dev/using-a-knowledge-graph-to-implement-a-devops-rag-application/) å¾ˆæœ‰å¸®åŠ©ã€‚\n",
    "\n",
    "### **å¤§è§„æ¨¡æ•°æ®å¤„ç†çš„æŒ‘æˆ˜**\n",
    "\n",
    "è™½ç„¶æˆ‘ä»¬çš„æ–¹æ³•è®©äººå¾ˆæœ‰æƒ³è±¡ç©ºé—´ï¼Œä½†å®ƒä»ç„¶åœ¨å¤„ç†å¤§é‡æ•°æ®æ—¶é¢ä¸´æŒ‘æˆ˜ï¼š\n",
    "\n",
    "* **é¢„å¤„ç†çš„å±€é™**ï¼šå°½ç®¡åšæ‘˜è¦æ˜¯ç›¸å¯¹ç®€å•çš„ï¼Œä½†å¼€å‘åœ¨å„ç§åœºæ™¯éƒ½æ™®éæœ‰æ•ˆçš„å±‚æ¬¡ç»“æ„æ˜¯å¾ˆæœ‰æŒ‘æˆ˜çš„ã€‚\n",
    "* **ç²’åº¦å’Œå¼•å¯¼ï¼ˆnavigationï¼‰æˆæœ¬**ï¼šåœ¨å±‚æ¬¡ç»“æ„ä¸­å®ç°ç²¾ç»†çš„ç²’åº¦å¯èƒ½éœ€è¦å¤§é‡èµ„æºï¼Œéœ€è¦å¤æ‚çš„æ•´åˆæˆ–å¾ˆå¤šåˆ†æ”¯æ¥ä¿æŒæ¯æ¬¡äº¤äº’çš„å¯ç®¡ç†ä¸Šä¸‹æ–‡å¤§å°ã€‚\n",
    "* **å¯¹ç²¾ç¡®æŒ‡ä»¤æ‰§è¡Œçš„ä¾èµ–**ï¼šç”¨æˆ‘ä»¬å½“å‰çš„å·¥å…·å¼•å¯¼å±‚æ¬¡ç»“æ„çš„æ£€ç´¢ï¼Œå¾ˆä¾èµ–åœ¨å¼ºå¤§çš„æŒ‡ä»¤å¾®è°ƒæ¨¡å‹ä¸Šåšå¤§é‡æç¤ºå·¥ç¨‹ã€‚æ¨ç†å»¶è¿Ÿå’Œå‚æ•°é¢„æµ‹ä¸­çš„é”™è¯¯é£é™©å¯èƒ½ä¼šå¾ˆå¤§ï¼Œå› æ­¤ç”¨ LLM å®ç°ä¼šæˆä¸ºä¸€ä¸ªæŒ‘æˆ˜ã€‚\n",
    "\n",
    "åœ¨æ‚¨ç»§ç»­å­¦ä¹ è¯¾ç¨‹çš„è¿‡ç¨‹ä¸­ï¼Œæƒ³æƒ³è¿™äº›æŒ‘æˆ˜æ˜¯é ä»€ä¹ˆæŠ€æœ¯è§£å†³çš„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdFSMXOVRzEa",
   "metadata": {
    "id": "cdFSMXOVRzEa"
   },
   "source": [
    "-----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **ç¬¬ 6 éƒ¨åˆ†ï¼š** æ€»ç»“\n",
    "\n",
    "æ­¤ notebook çš„ç›®æ ‡æ˜¯ä»‹ç»èŠå¤©æ¨¡å‹å¦‚ä½•å¤„ç†å¤§å‹æ–‡æ¡£ã€‚ä¸‹ä¸€ä¸ª notebookï¼Œæˆ‘ä»¬å°†ç ”ç©¶ä¸€ä¸ªæœ‰ä¸åŒä¼˜åŠ£åŠ¿çš„è¡¥å……å·¥å…·ï¼š**ä½¿ç”¨åµŒå…¥æ¨¡å‹è¿›è¡Œè¯­ä¹‰æ£€ç´¢**ã€‚\n",
    "\n",
    "### <font color=\"#76b900\">**éå¸¸å¥½ï¼**</font>\n",
    "\n",
    "### **æ¥ä¸‹æ¥ï¼š**\n",
    "1. **[å¯é€‰]** å›é¡¾ notebook é¡¶éƒ¨çš„â€œæ€è€ƒé—®é¢˜â€ã€‚\n",
    "2. **[å¯é€‰]** æ­¤ notebook åŒ…å«ä¸€äº›åŸºæœ¬çš„æ–‡æ¡£å¤„ç†é“¾ï¼Œä½†ä¸æ¶‰åŠ [Map Reduce](https://python.langchain.com/docs/modules/chains/document/map_reduce) å’Œ [Map Rerank](https://python.langchain.com/docs/modules/chains/document/map_rerank) é“¾ï¼Œå®ƒä»¬ä¹Ÿéå¸¸æœ‰ç”¨ï¼Œè€Œä¸”æ˜¯åŸºäºå¤§è‡´ç›¸åŒçš„ç›´è§‰æ„å»ºçš„ã€‚äº†è§£ä¸€ä¸‹æœ‰åŠ©äºæ‚¨åŠ æ·±ç†è§£ï¼"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
